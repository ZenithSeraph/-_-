{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Collection of Predictive Words per Personality Trait using LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/cleaned/expanded_mbti_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>comp_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>neu_score</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>post_count</th>\n",
       "      <th>avg_word_count</th>\n",
       "      <th>posts_cleaned</th>\n",
       "      <th>cleaned_comp_score</th>\n",
       "      <th>...</th>\n",
       "      <th>diff_comp_init-no_punct</th>\n",
       "      <th>E_I</th>\n",
       "      <th>N_S</th>\n",
       "      <th>F_T</th>\n",
       "      <th>J_P</th>\n",
       "      <th>E_I_code</th>\n",
       "      <th>N_S_code</th>\n",
       "      <th>F_T_code</th>\n",
       "      <th>J_P_code</th>\n",
       "      <th>type_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>[\"'http://www.youtube.com/watch?v=qsXHcwe3krw\"...</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.116</td>\n",
       "      <td>50</td>\n",
       "      <td>90</td>\n",
       "      <td>['enfp and intj moments sportscenter not top t...</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>[\"'I'm finding the lack of me in these posts v...</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.180</td>\n",
       "      <td>50</td>\n",
       "      <td>138</td>\n",
       "      <td>[\"'I'm finding the lack of me in these posts v...</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  comp_score  \\\n",
       "0  INFJ  [\"'http://www.youtube.com/watch?v=qsXHcwe3krw\"...      0.9877   \n",
       "1  ENTP  [\"'I'm finding the lack of me in these posts v...      0.9994   \n",
       "\n",
       "   neg_score  neu_score  pos_score  post_count  avg_word_count  \\\n",
       "0      0.054      0.829      0.116          50              90   \n",
       "1      0.068      0.752      0.180          50             138   \n",
       "\n",
       "                                       posts_cleaned  cleaned_comp_score  ...  \\\n",
       "0  ['enfp and intj moments sportscenter not top t...              0.9839  ...   \n",
       "1  [\"'I'm finding the lack of me in these posts v...              0.9993  ...   \n",
       "\n",
       "   diff_comp_init-no_punct  E_I  N_S  F_T  J_P E_I_code  N_S_code  F_T_code  \\\n",
       "0                   0.0074    I    N    F    J        0         1         1   \n",
       "1                   0.0009    E    N    T    P        1         1         0   \n",
       "\n",
       "  J_P_code  type_code  \n",
       "0        1        111  \n",
       "1        0       1100  \n",
       "\n",
       "[2 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Custom Stopword Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/full_stopwords.txt', 'r') as filehandle:\n",
    "    custom_stopwords = [words.rstrip() for words in filehandle.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### TFDIF Vectorizer Model: using *stop_words=custom_stopwords*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['E_I', 'N_S', 'F_T', 'J_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG: E_I...1\n",
      "FLAG: E_I...2\n",
      "FLAG: E_I...3\n",
      "FLAG: E_I...4\n",
      "FLAG: N_S...1\n",
      "FLAG: N_S...2\n",
      "FLAG: N_S...3\n",
      "FLAG: N_S...4\n",
      "FLAG: F_T...1\n",
      "FLAG: F_T...2\n",
      "FLAG: F_T...3\n",
      "FLAG: F_T...4\n",
      "FLAG: J_P...1\n",
      "FLAG: J_P...2\n",
      "FLAG: J_P...3\n",
      "FLAG: J_P...4\n"
     ]
    }
   ],
   "source": [
    "targets_dict_tf = {}\n",
    "\n",
    "for target in targets:   \n",
    "    target_dict_L1 = {}\n",
    "    target_dict_L2 = {}\n",
    "    ngram_pos_dict = {}\n",
    "    ngram_neg_dict = {}\n",
    "\n",
    "    for i in range(1,5):\n",
    "        word_pos_dict = {}\n",
    "        word_neg_dict = {}\n",
    "        \n",
    "        print('FLAG: '+target+'...'+str(i))\n",
    "        classifier = LogisticRegression(C=1.0, class_weight=\"balanced\", max_iter = 10_000)\n",
    "        tf_idf = Pipeline([\n",
    "                    ('tfidf', TfidfVectorizer(stop_words=custom_stopwords, ngram_range=(i,i), min_df=10)),\n",
    "                    (\"classifier\", classifier)])\n",
    "        tf_idf.fit(data.posts_no_digits, data[target])\n",
    "        coefs = tf_idf.named_steps[\"classifier\"].coef_\n",
    "        coefs.tolist()\n",
    "        feature_names = tf_idf.named_steps[\"tfidf\"].get_feature_names()\n",
    "        coefs_and_features = list(zip(coefs[0], feature_names))\n",
    "        positive_results = sorted(coefs_and_features, key=lambda x: x[0], reverse=True)[:30]\n",
    "        negative_results = sorted(coefs_and_features, key=lambda x: x[0])[:30]\n",
    "\n",
    "        for result in positive_results:\n",
    "            word_pos_dict['word_'+str(len(word_pos_dict)+1)] = {'coef':abs(result[0]), 'word':result[1]}\n",
    "        ngram_pos_dict['ngram_'+str(i)] = word_pos_dict\n",
    "        target_dict_L1.update(ngram_pos_dict)\n",
    "\n",
    "        for result in negative_results:\n",
    "            word_neg_dict['word_'+str(len(word_neg_dict)+1)] = {'coef':abs(result[0]), 'word':result[1]}\n",
    "        ngram_neg_dict['ngram_'+str(i)] = word_neg_dict\n",
    "        target_dict_L2.update(ngram_neg_dict)\n",
    "    \n",
    "    targets_dict_tf[target[0]] = target_dict_L1\n",
    "    targets_dict_tf[target[2]] = target_dict_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">E</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">ngram_1</th>\n",
       "      <th>word_1</th>\n",
       "      <td>2.35492</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_2</th>\n",
       "      <td>2.22272</td>\n",
       "      <td>games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_3</th>\n",
       "      <td>2.10766</td>\n",
       "      <td>feel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_4</th>\n",
       "      <td>1.98206</td>\n",
       "      <td>mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_5</th>\n",
       "      <td>1.96383</td>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">P</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">ngram_4</th>\n",
       "      <th>word_26</th>\n",
       "      <td>0.641491</td>\n",
       "      <td>could anthropomorphize animal would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_27</th>\n",
       "      <td>0.641491</td>\n",
       "      <td>would animal would represent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_28</th>\n",
       "      <td>0.618634</td>\n",
       "      <td>often think society downhill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_29</th>\n",
       "      <td>0.611839</td>\n",
       "      <td>score scale ranging low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_30</th>\n",
       "      <td>0.60057</td>\n",
       "      <td>usually get along well</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       coef                                 word\n",
       "E ngram_1 word_1    2.35492                               family\n",
       "          word_2    2.22272                                games\n",
       "          word_3    2.10766                                 feel\n",
       "          word_4    1.98206                                 mind\n",
       "          word_5    1.96383                                dream\n",
       "...                     ...                                  ...\n",
       "P ngram_4 word_26  0.641491  could anthropomorphize animal would\n",
       "          word_27  0.641491         would animal would represent\n",
       "          word_28  0.618634         often think society downhill\n",
       "          word_29  0.611839              score scale ranging low\n",
       "          word_30   0.60057               usually get along well\n",
       "\n",
       "[960 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindexed_target_dict = {}\n",
    "\n",
    "for targetKey, ngramDict in targets_dict_tf.items():\n",
    "    for ngramKey, wordDict in ngramDict.items():\n",
    "        for word_indexKey, word_indexValue in wordDict.items():\n",
    "            reindexed_target_dict[(targetKey, ngramKey, word_indexKey)] = word_indexValue\n",
    "\n",
    "ngrams_tf_df = pd.DataFrame(reindexed_target_dict).T\n",
    "ngrams_tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLAG: E_I...1\n",
      "FLAG: E_I...2\n",
      "FLAG: E_I...3\n",
      "FLAG: E_I...4\n",
      "FLAG: N_S...1\n",
      "FLAG: N_S...2\n",
      "FLAG: N_S...3\n",
      "FLAG: N_S...4\n",
      "FLAG: F_T...1\n",
      "FLAG: F_T...2\n",
      "FLAG: F_T...3\n",
      "FLAG: F_T...4\n",
      "FLAG: J_P...1\n",
      "FLAG: J_P...2\n",
      "FLAG: J_P...3\n",
      "FLAG: J_P...4\n"
     ]
    }
   ],
   "source": [
    "targets_dict_cv = {}\n",
    "\n",
    "for target in targets:   \n",
    "    target_dict_L1 = {}\n",
    "    target_dict_L2 = {}\n",
    "    ngram_pos_dict = {}\n",
    "    ngram_neg_dict = {}\n",
    "\n",
    "    for i in range(1,5):\n",
    "        word_pos_dict = {}\n",
    "        word_neg_dict = {}\n",
    "        \n",
    "        print('FLAG: '+target+'...'+str(i))\n",
    "        classifier = LogisticRegression(C=1.0, class_weight=\"balanced\", max_iter = 10_000)\n",
    "        cvect = Pipeline([\n",
    "                    ('countvect', CountVectorizer(stop_words=custom_stopwords, ngram_range=(i,i), min_df=10)),\n",
    "                    (\"classifier\", classifier)])\n",
    "        cvect.fit(data.posts_no_digits, data[target])\n",
    "        coefs = cvect.named_steps[\"classifier\"].coef_\n",
    "        coefs.tolist()\n",
    "        feature_names = cvect.named_steps[\"countvect\"].get_feature_names()\n",
    "        coefs_and_features = list(zip(coefs[0], feature_names))\n",
    "        positive_results = sorted(coefs_and_features, key=lambda x: x[0], reverse=True)[:30]\n",
    "        negative_results = sorted(coefs_and_features, key=lambda x: x[0])[:30]\n",
    "\n",
    "        for result in positive_results:\n",
    "            word_pos_dict['word_'+str(len(word_pos_dict)+1)] = {'coef':abs(result[0]), 'word':result[1]}\n",
    "        ngram_pos_dict['ngram_'+str(i)] = word_pos_dict\n",
    "        target_dict_L1.update(ngram_pos_dict)\n",
    "\n",
    "        for result in negative_results:\n",
    "            word_neg_dict['word_'+str(len(word_neg_dict)+1)] = {'coef':abs(result[0]), 'word':result[1]}\n",
    "        ngram_neg_dict['ngram_'+str(i)] = word_neg_dict\n",
    "        target_dict_L2.update(ngram_neg_dict)\n",
    "    \n",
    "    targets_dict_cv[target[0]] = target_dict_L1\n",
    "    targets_dict_cv[target[2]] = target_dict_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">E</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">ngram_1</th>\n",
       "      <th>word_1</th>\n",
       "      <td>0.848481</td>\n",
       "      <td>organize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_2</th>\n",
       "      <td>0.741726</td>\n",
       "      <td>letting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_3</th>\n",
       "      <td>0.713516</td>\n",
       "      <td>spoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_4</th>\n",
       "      <td>0.711239</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_5</th>\n",
       "      <td>0.702281</td>\n",
       "      <td>offense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">P</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">ngram_4</th>\n",
       "      <th>word_26</th>\n",
       "      <td>0.589868</td>\n",
       "      <td>ever consider going bungee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_27</th>\n",
       "      <td>0.589868</td>\n",
       "      <td>going bungee jumping skydiving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_28</th>\n",
       "      <td>0.587306</td>\n",
       "      <td>thank much taking time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_29</th>\n",
       "      <td>0.581126</td>\n",
       "      <td>welcome hope enjoy time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_30</th>\n",
       "      <td>0.577456</td>\n",
       "      <td>monty python holy grail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       coef                            word\n",
       "E ngram_1 word_1   0.848481                        organize\n",
       "          word_2   0.741726                         letting\n",
       "          word_3   0.713516                          spoken\n",
       "          word_4   0.711239                          severe\n",
       "          word_5   0.702281                         offense\n",
       "...                     ...                             ...\n",
       "P ngram_4 word_26  0.589868      ever consider going bungee\n",
       "          word_27  0.589868  going bungee jumping skydiving\n",
       "          word_28  0.587306          thank much taking time\n",
       "          word_29  0.581126         welcome hope enjoy time\n",
       "          word_30  0.577456         monty python holy grail\n",
       "\n",
       "[960 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reindexed_target_dict = {}\n",
    "\n",
    "for targetKey, ngramDict in targets_dict_cv.items():\n",
    "    for ngramKey, wordDict in ngramDict.items():\n",
    "        for word_indexKey, word_indexValue in wordDict.items():\n",
    "            reindexed_target_dict[(targetKey, ngramKey, word_indexKey)] = word_indexValue\n",
    "\n",
    "ngrams_cv_df = pd.DataFrame(reindexed_target_dict).T\n",
    "ngrams_cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_cv_df.to_csv('ngrams_cv_logreg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_tf_df.to_csv('ngrams_tf_logreg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
