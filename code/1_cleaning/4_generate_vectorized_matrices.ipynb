{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Vectorized Text Matrices Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Future Usage of Vectorized Matrices Files Unadvisable</b><br>\n",
    "Future models should implement vectorizors that implement max_feature reduction during construction to prevent future overdetermination</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import scipy.sparse\n",
    "import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA IMPORT\n",
    "\n",
    "data = pd.read_csv('../data/cleaned/expanded_mbti_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'posts', 'comp_score', 'neg_score', 'neu_score', 'pos_score',\n",
       "       'post_count', 'avg_word_count', 'posts_cleaned', 'cleaned_comp_score',\n",
       "       'cleaned_neg_score', 'cleaned_neu_score', 'cleaned_pos_score',\n",
       "       'post_count_cleaned', 'avg_word_count_cleaned', 'posts_no_digits',\n",
       "       'post_count_no_digits', 'avg_word_count_no_digits', 'posts_no_punct',\n",
       "       'no_punct_comp_score', 'no_punct_neg_score', 'no_punct_neu_score',\n",
       "       'no_punct_pos_score', 'diff_post_count_init-cleaned',\n",
       "       'diff_word_count_init-cleaned', 'diff_post_count_cleaned-no_digits',\n",
       "       'diff_word_count_cleaned-no_digits', 'diff_post_count_init-no_digits',\n",
       "       'diff_word_count_init-no_digits', 'diff_comp_init-clean',\n",
       "       'diff_comp_clean-no_punct', 'diff_comp_init-no_punct', 'E_I', 'N_S',\n",
       "       'F_T', 'J_P', 'E_I_code', 'N_S_code', 'F_T_code', 'J_P_code',\n",
       "       'type_code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8675 entries, 0 to 8674\n",
      "Data columns (total 41 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   type                               8675 non-null   object \n",
      " 1   posts                              8675 non-null   object \n",
      " 2   comp_score                         8675 non-null   float64\n",
      " 3   neg_score                          8675 non-null   float64\n",
      " 4   neu_score                          8675 non-null   float64\n",
      " 5   pos_score                          8675 non-null   float64\n",
      " 6   post_count                         8675 non-null   int64  \n",
      " 7   avg_word_count                     8675 non-null   int64  \n",
      " 8   posts_cleaned                      8675 non-null   object \n",
      " 9   cleaned_comp_score                 8675 non-null   float64\n",
      " 10  cleaned_neg_score                  8675 non-null   float64\n",
      " 11  cleaned_neu_score                  8675 non-null   float64\n",
      " 12  cleaned_pos_score                  8675 non-null   float64\n",
      " 13  post_count_cleaned                 8675 non-null   int64  \n",
      " 14  avg_word_count_cleaned             8675 non-null   int64  \n",
      " 15  posts_no_digits                    8675 non-null   object \n",
      " 16  post_count_no_digits               8675 non-null   int64  \n",
      " 17  avg_word_count_no_digits           8675 non-null   int64  \n",
      " 18  posts_no_punct                     8675 non-null   object \n",
      " 19  no_punct_comp_score                8675 non-null   float64\n",
      " 20  no_punct_neg_score                 8675 non-null   float64\n",
      " 21  no_punct_neu_score                 8675 non-null   float64\n",
      " 22  no_punct_pos_score                 8675 non-null   float64\n",
      " 23  diff_post_count_init-cleaned       8675 non-null   int64  \n",
      " 24  diff_word_count_init-cleaned       8675 non-null   int64  \n",
      " 25  diff_post_count_cleaned-no_digits  8675 non-null   int64  \n",
      " 26  diff_word_count_cleaned-no_digits  8675 non-null   int64  \n",
      " 27  diff_post_count_init-no_digits     8675 non-null   int64  \n",
      " 28  diff_word_count_init-no_digits     8675 non-null   int64  \n",
      " 29  diff_comp_init-clean               8675 non-null   float64\n",
      " 30  diff_comp_clean-no_punct           8675 non-null   float64\n",
      " 31  diff_comp_init-no_punct            8675 non-null   float64\n",
      " 32  E_I                                8675 non-null   object \n",
      " 33  N_S                                8675 non-null   object \n",
      " 34  F_T                                8675 non-null   object \n",
      " 35  J_P                                8675 non-null   object \n",
      " 36  E_I_code                           8675 non-null   int64  \n",
      " 37  N_S_code                           8675 non-null   int64  \n",
      " 38  F_T_code                           8675 non-null   int64  \n",
      " 39  J_P_code                           8675 non-null   int64  \n",
      " 40  type_code                          8675 non-null   int64  \n",
      "dtypes: float64(15), int64(17), object(9)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/full_stopwords.txt', 'r') as filehandle:\n",
    "    custom_stopwords = [words.rstrip() for words in filehandle.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    text = nlp(text)\n",
    "    lemma_text = [word.lemma_ for word in text if not word.is_punct]\n",
    "    return lemma_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CountVectorized matrix without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(tokenizer=custom_tokenizer, stop_words = custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_vect = cv.fit_transform(data['posts_no_punct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('countvect_matrix_lemma.npz', cv_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TFIDF-Vectorized matrix without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=custom_tokenizer, stop_words = custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = tfidf.fit_transform(data['posts_no_punct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('tfidfvect_matrix_lemma.npz', tfidf_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spacy-WordEmbedded Vectorized matrix without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component(\"stopwords_component\")\n",
    "def custom_component(doc):\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    results = [word.text.lower() for word in doc if word.text.lower() not in custom_stopwords]    \n",
    "    doc = nlp(\" \".join(results))\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordVectorTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, model = 'en_core_web_lg'):\n",
    "        self.model = model\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        nlp = spacy.load(self.model)\n",
    "        nlp.add_pipe('stopwords_component', after='tok2vec')\n",
    "        return np.concatenate([nlp(doc).vector.reshape(1, -1) for doc in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvt = WordVectorTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvt_vect = wvt.fit(data['posts_no_punct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvt_vect = wvt.transform(data['posts_no_punct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('spacyvect_matrix_lemma.npz', wvt_vect)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
